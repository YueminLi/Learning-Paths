---
title: "Lab10-Unsupervised Learning"
output: html_document
---

# packages and libraries
```{r}

```


# Principal Components Analysis
```{r}
# rows of the data set
states = row.names(USArrests)
states
# columns of the data set
names(USArrests)
# variable mean and variance
apply(USArrests, 2, mean)
apply(USArrests, 2, var)

# pca
pr.out = prcomp(USArrests, scale=TRUE)
names(pr.out)
pr.out$center
pr.out$scale
pr.out$rotation

# plot the first two principal components
biplot(pr.out, scale=0)

# calculate the proportion of variance explained (PVE) by each principal component
pr.out$sdev
pr.var = pr.out$sdev^2
pr.var
pve = pr.var/sum(pr.var)
pve

# plot PVE
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1), type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1), type='b')
```


# Clustering
## K-Means Clustering
```{r}
set.seed(2)
x = matrix(rnorm(50*2), ncol=2)
x[1:25,1] = x[1:25,1]+3
x[1:25,2] = x[1:25,2]-4

# K=2
km.out = kmeans(x, 2, nstart=20)
plot(x, col=(km.out$cluster+1), main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)

# K=3
set.seed(4)
km.out = kmeans(x,3,nstart=20)
km.out
plot(x, col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
```

## Hierarchical Clustering
```{r}
# complete linkage
hc.complete = hclust(dist(x), method="complete")
# average linkage
hc.average = hclust(dist(x), method="average")
# single linkage
hc.single = hclust(dist(x), method="single")

par(mfrow=c(1,3))
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)

cutree(hc.complete, 2)
cutree(hc.average, 2)
cutree(hc.single, 4)

# scale
xsc = scale(x, center=FALSE, scale=TRUE)
plot(hclust(dist(xsc), method="complete"), main="Hierarchical Clustering with Scaled Observations")
```









