---
title: "Lab 7-Non-Linear Modeling"
output: html_document
---

# Packages and library
```{r}
install.packages("ISLR")
install.packages("gam")
install.packages("akima")
```

```{r}
library(ISLR)
attach(Wage)
library(splines)
library(gam)
library(akima)
```

# Polynomial Regression and Step Functions
## Polynomial Linear Regression
```{r}
# orthogonal polynomial, reduce collinearity
fit = lm(wage ~ poly(age, 4), data=Wage)
coef(summary(fit))

# raw polynomial
fit2 = lm(wage ~ poly(age, 4, raw=TRUE), data=Wage)
coef(summary(fit2))

# similar methods to fit raw polynomial model
fit2a = lm(wage ~ age + I(age^2) + I(age^3) + I(age^4), data=Wage)
coef(fit2a)

fit2b = lm(wage ~ cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)

# create a grid of values for age at which we want predictions
agelims = range(age)
age.grid = seq(from=agelims[1], to=agelims[2])
# obtain predictions and standard error
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)

# plot the data
par(mfrow=c(1,2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 4, 0))
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Degree -4 Polynomial", outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col="blue")
matlines(age.grid, se.bands, lwd=1, col="blue", lty=3)

# decide on the degree of the polynomial using ANOVA
# null hypothesis: a model M1 is sufficient to explain the data
# alternative hypothesis: a more complex model M2 is required
# M1 and M2 must be nested models: the predictors in M1 must be a subset of the predictors in M2
fit.1 = lm(wage ~ age, data=Wage)
fit.2 = lm(wage ~ poly(age, 2), data=Wage)
fit.3 = lm(wage ~ poly(age, 3), data=Wage)
fit.4 = lm(wage ~ poly(age, 4), data=Wage)
fit.5 = lm(wage ~ poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)

# poly() creates the same p-value as in ANOVA
coef(summary(fit.5))

```

## Polynomial Logistic Regression
```{r}
# predict whether an individual earns more than $250,000 per year
fit = glm(I(wage>250) ~ poly(age, 4), data=Wage, family=binomial)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
pfit = exp(preds$fit)/(1 + exp(preds$fit))
se.bands.logit = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)

# plot the data
plot(age, I(wage>250), xlim=agelims, type="n", ylim=c(0,.2))
points(jitter(age), I((wage>250)/5), cex=.5, pch="|", col="darkgrey")
lines(age.grid, pfit, lwd=2, col="blue")
matlines(age.grid, se.bands, lwd=1, col="blue", lty=3)

```

## Step Function
```{r}
table(cut(age, 4))
fit = lm(wage ~ cut(age, 4), data=Wage)
coef(summary(fit))
```


# Splines
```{r}
# cubic spline
fit = lm(wage ~ bs(age, knots=c(25,40,60)), data=Wage)
pred = predict(fit, newdata=list(age=age.grid), se=TRUE)
plot(age, wage, col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty="dashed")
lines(age.grid, pred$fit-2*pred$se, lty="dashed")

# natural spline
fit2 = lm(wage ~ ns(age, df=4), data=Wage)
pred2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
lines(age.grid, pred2$fit, col="red", lwd=2)


# smooth spline
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Smoothing Spline")
fit = smooth.spline(age, wage, df=16)
fit2 = smooth.spline(age, wage, cv=TRUE)
fit2$df
lines(fit, col="red", lwd=2)
lines(fit2, col="blue", lwd=2)
legend("topright", legend=c("16 DF","6.8 DF"), col=c("red","blue"), 
       lty=1, lwd=2, cex=.8)

# local regression
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Local Regression")
fit = loess(wage ~ age, span=.2, data=Wage)
fit2 = loess(wage ~ age, span=.5, data=Wage)
lines(age.grid, predict(fit, data.frame(age=age.grid)), col="red", lwd=2)
lines(age.grid, predict(fit2, data.frame(age=age.grid)), col="blue", lwd=2)
legend("topright", legend=c("Span=0.2","Span=0.5"), col=c("red","blue"), lty=1, lwd=2, cex=.8)

```


# GAMs
```{r}
# GAM with natural spline
gam1 = lm(wage ~ ns(year,4) + ns(age,5) + education, data=Wage)

# GAM with smoothing spline
gam.m3 = gam(wage ~ s(year,4) + s(age,5) + education, data=Wage)

# plot the data
par(mfow=c(1,3))
plot(gam.m3, se=TRUE, col="blue")
plot.gam(gam1, se=TRUE, col="red")

# ANOVA test to determine which the three models is the best
# M1: GAM that excludes year
# M2: GAM that uses a linear function of year
# M3: GAM that uses a spline function of year
gam.m1 = gam(wage ~ s(age,5) + education, data=Wage)
gam.m2 = gam(wage ~ year + s(age,5) + education, data=Wage)
anova(gam.m1, gam.m2, gam.m3, test="F")
summary(gam.m3)

# predict
preds = predict(gam.m2, newdata=Wage)

# GAM with local regression
gam.lo = gam(wage ~ s(year, df=4) + lo(age,span=0.7) + education, data=Wage)
plot.gam(gam.lo, se=TRUE, col="green")

# add interaction terms
gam.lo.i = gam(wage ~ lo(year, age, span=0.5) + education, data=Wage)

# plot the data
plot(gam.lo.i)

# GAM with logistic regression
gam.lr = gam(I(wage>250) ~ year + s(age,df=5) + education, family=binomial, data=Wage)
par(mfrow=c(1,3))
plot(gam.lr, se=TRUE, col="green")
table(education, I(wage>250))

# remove the education category of "< HS Grad"
gam.lr.s = gam(I(wage>250) ~ year + s(age,df=5) + education, family=binomial, data=Wage, subset=(education!="1. < HS Grad"))
plot(gam.lr.s, se=TRUE, col="green")
```
