---
title: "Lab5-Cross Validation and the Bootstrap"
output: html_document
---

```{r}
install.packages('ISLR')
library(ISLR)
library(boot)
```

# 1. The Validation Set Approach
```{r}
set.seed(1)
# split samples into two sets
train = sample(392, 196)

# use training set to train the linear regression model
lm.fit = lm(mpg ~ horsepower, data=Auto, subset=train)
attach(Auto)
# calculate MSE of the 196 observations in the validation set
mean((mpg - predict(lm.fit, Auto))[-train]^2)

# train the polynomial regression model
lm.fit2 = lm(mpg ~ poly(horsepower, 2), data=Auto, subset=train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)

# train the cubic regression model
lm.fit3 = lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
```

# 2. Leave-One-Out Cross-Validation
```{r}
# train the linear regression model
glm.fit = glm(mpg ~ horsepower, data=Auto)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta

# train the polynomial regression models
cv.error = rep(0,5)
for (i in 1:5){
  glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
  cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
```

# 3. K-fold Cross Validation
```{r}
set.seed(17)
cv.error.10 = rep(0,10)
for (i in 1:10){
  glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
  cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
```

# 4. The Bootstrap
```{r}
alpha.fn = function(data, index){
  X = data$X[index]
  Y = data$Y[index]
  return((var(Y) - cov(X,Y))/(var(X) + var(Y) - 2*cov(X,Y)))
}
boot(Portfolio, statistic=alpha.fn, R=1000)

# estimate the accuracy of a linear regression model
boot.fn = function(data,index)
  return(coef(lm(mpg ~ horsepower, data=data, subset=index)))
boot.fn(Auto, 1:392)
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data=Auto))$coef
```